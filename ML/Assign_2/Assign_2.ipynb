{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3: Implementation of Neural Networks from Scratch Using NumPy and Comparison with Sklearn (20 marks):\n",
    "  \n",
    "    1. Load and preprocess the MNIST Digits Dataset. (3 marks)\n",
    "    2. Implement a neural network with one input layer, one hidden layer, and one output layer using NumPy. (5 marks)\n",
    "    3. Train the neural network with various hyperparameters (e.g., learning rate, number of hidden nodes). (3 marks)\n",
    "    4. Evaluate the performance of the neural network on the testing set. (2 marks)\n",
    "    5. Implement the same neural network using sklearn and compare the results with the NumPy implementation. (4 marks)\n",
    "    6. Plot the training and validation loss/accuracy curves (for both experiments). (3 marks) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix,ConfusionMatrixDisplay, classification_report\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.datasets import fetch_openml\n",
    "\n",
    "# X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "# X[\"Y\"] = y\n",
    "# X.to_csv(\"mnist_784.csv\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_784_df = pd.read_csv(\"mnist_784.csv\")\n",
    "# display(mnist_784_df.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0, x)\n",
    "\n",
    "def relu_derivative(x):\n",
    "    return np.where(x > 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.output_dim = output_dim\n",
    "        \n",
    "        self.weights1 = np.random.rand(input_dim, hidden_dim)\n",
    "        self.weights2 = np.random.rand(hidden_dim, output_dim)\n",
    "        self.bias1 = np.zeros((1, hidden_dim))\n",
    "        self.bias2 = np.zeros((1, output_dim))\n",
    "\n",
    "    def forward_propagation(self, inputs):\n",
    "\n",
    "        hidden_layer_input = np.dot(inputs, self.weights1) + self.bias1\n",
    "        hidden_layer_output = relu(hidden_layer_input)\n",
    "        \n",
    "        output_layer_input = np.dot(hidden_layer_output, self.weights2) + self.bias2\n",
    "        output_layer_output = sigmoid(output_layer_input)\n",
    "        \n",
    "        return hidden_layer_output, output_layer_output\n",
    "\n",
    "    def backward_propagation(self, inputs, targets, hidden_layer_output, output_layer_output):\n",
    "\n",
    "        d_output = 2 * (output_layer_output - targets)\n",
    "        d_weights2 = np.dot(hidden_layer_output.T, d_output * sigmoid_derivative(output_layer_output))\n",
    "        d_bias2 = np.sum(d_output * sigmoid_derivative(output_layer_output), axis=0, keepdims=True)\n",
    "        \n",
    "        d_hidden_layer = np.dot(d_output * sigmoid_derivative(output_layer_output), self.weights2.T) * relu_derivative(hidden_layer_output)\n",
    "        d_weights1 = np.dot(inputs.T, d_hidden_layer)\n",
    "        d_bias1 = np.sum(d_hidden_layer, axis=0, keepdims=True)\n",
    "        \n",
    "        return d_weights1, d_bias1, d_weights2, d_bias2\n",
    "\n",
    "    def update_weights(self, d_weights1, d_bias1, d_weights2, d_bias2, learning_rate):\n",
    "        self.weights1 -= learning_rate * d_weights1\n",
    "        self.bias1 -= learning_rate * d_bias1\n",
    "        self.weights2 -= learning_rate * d_weights2\n",
    "        self.bias2 -= learning_rate * d_bias2\n",
    "    \n",
    "    def runner(self, inputs, targets, epochs, learning_rate):\n",
    "        for i in range(epochs):\n",
    "            hidden_layer_output, output_layer_output = self.forward_propagation(inputs)\n",
    "            d_weights1, d_bias1, d_weights2, d_bias2 = self.backward_propagation(inputs, targets, hidden_layer_output, output_layer_output)\n",
    "            self.update_weights(d_weights1, d_bias1, d_weights2, d_bias2, learning_rate)\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Loss: {np.mean(np.square(output_layer_output - targets))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = mnist_784_df.drop(columns=\"Y\").values\n",
    "targets = mnist_784_df[\"Y\"].values\n",
    "result = np.where(targets == 5, targets, 0)\n",
    "\n",
    "IL_n = mnist_784_df.shape[-1]-1\n",
    "n_neurons_HL = int(np.sqrt(IL_n-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the array\n",
    "max_values = np.max(inputs, axis=0)\n",
    "min_values = np.min(inputs, axis=0)\n",
    "\n",
    "normalized_array = (inputs - min_values) / (max_values - min_values)\n",
    "normalized_array = np.nan_to_num(normalized_array)  # Replace NaN values with 0\n",
    "\n",
    "# print(normalized_array[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scaler = StandardScaler()\n",
    "inputs = pd.DataFrame(scaler.fit_transform(inputs), columns=inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    inputs, result,\n",
    "    test_size=0.20, random_state=42,\n",
    "    stratify=result,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork(input_dim=IL_n, hidden_dim=n_neurons_HL, output_dim=1)\n",
    "\n",
    "\n",
    "learning_rate = 0.1\n",
    "epochs = 10000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    hidden_layer_output, output_layer_output = nn.forward_propagation(inputs)\n",
    "    d_weights1, d_bias1, d_weights2, d_bias2 = nn.backward_propagation(inputs, targets, hidden_layer_output, output_layer_output)\n",
    "    nn.update_weights(d_weights1, d_bias1, d_weights2, d_bias2, learning_rate)\n",
    "    \n",
    "    # Print loss every 1000 epochs\n",
    "    if epoch % 1000 == 0:\n",
    "        loss = np.mean(np.square(output_layer_output - targets))\n",
    "        print(f\"Epoch {epoch+1}, Loss: {loss}\")\n",
    "\n",
    "# Final predictions\n",
    "_, final_output = nn.forward_propagation(inputs)\n",
    "print(\"Final Predictions:\")\n",
    "print(final_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron:\n",
    "    def __init__(self,value):\n",
    "        self.value = value\n",
    "class hidden_layer  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class aHL:\n",
    "    def __init__(self,mnist_784_df):\n",
    "\n",
    "    \n",
    "    def forward_prop_relu(self,input,weight):\n",
    "        return np.maximum(0, input*weight)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.to_csv(\"mnist_784.csv\",index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(X.head().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(X, columns=[f'Pixel_{i}'for i in range(X.shape[-1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
