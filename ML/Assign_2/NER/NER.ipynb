{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/as3091/IITJ/blob/NER/ML/Assign_2/NER/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3LJz_m8KBByu"
      },
      "source": [
        "Title: Named Entity Recognition\n",
        "\n",
        "Description:\n",
        "In this NER-focused project, you will design and develop a custom Named Entity Recognition (NER) system for text analysis. Named Entity Recognition involves identifying and classifying specific entities, such as names, dates, locations, and more, within unstructured text data. Your project will offer a versatile NER solution that will work well on the provided dataset.\n",
        "\n",
        "Dataset: Named Entity Recognition (NER) Corpus (kaggle.com)\n",
        "\n",
        "https://www.kaggle.com/datasets/naseralqaydeh/named-entity-recognition-ner-corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:43:27.954258Z",
          "iopub.status.busy": "2025-04-08T06:43:27.954071Z",
          "iopub.status.idle": "2025-04-08T06:43:36.402523Z",
          "shell.execute_reply": "2025-04-08T06:43:36.401044Z",
          "shell.execute_reply.started": "2025-04-08T06:43:27.954237Z"
        },
        "id": "sIOfipnGBByw",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install tensorflow --quiet\n",
        "# !pip install keras --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:43:36.403769Z",
          "iopub.status.busy": "2025-04-08T06:43:36.403514Z",
          "iopub.status.idle": "2025-04-08T06:43:58.766901Z",
          "shell.execute_reply": "2025-04-08T06:43:58.766018Z",
          "shell.execute_reply.started": "2025-04-08T06:43:36.403742Z"
        },
        "id": "5YUItkm-BByx",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-04-13 12:52:30.792704: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2025-04-13 12:52:30.812073: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-04-13 12:52:30.960820: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-04-13 12:52:31.106999: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1744548751.294798   11599 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1744548751.333751   11599 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1744548751.582001   11599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744548751.582058   11599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744548751.582059   11599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1744548751.582061   11599 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-04-13 12:52:31.609027: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import warnings,sys, ast, pickle\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import display, HTML\n",
        "# import matplotlib.pyplot as plt\n",
        "from pprint import pprint\n",
        "\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "from keras.layers import Dense, Input, Bidirectional, LSTM, Embedding, Dropout\n",
        "from keras.models import Model\n",
        "from keras.losses import SparseCategoricalCrossentropy\n",
        "from keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import load_model\n",
        "# from keras.random import SeedGenerator\n",
        "\n",
        "# seed_gen = SeedGenerator(seed=42)\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "import datetime as dt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:43:58.770499Z",
          "iopub.status.busy": "2025-04-08T06:43:58.770237Z",
          "iopub.status.idle": "2025-04-08T06:44:02.246367Z",
          "shell.execute_reply": "2025-04-08T06:44:02.244933Z",
          "shell.execute_reply.started": "2025-04-08T06:43:58.770475Z"
        },
        "id": "XlhvMq8SBByy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# !pip install kagglehub --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:02.247993Z",
          "iopub.status.busy": "2025-04-08T06:44:02.247702Z",
          "iopub.status.idle": "2025-04-08T06:44:14.598820Z",
          "shell.execute_reply": "2025-04-08T06:44:14.598058Z",
          "shell.execute_reply.started": "2025-04-08T06:44:02.247964Z"
        },
        "id": "gqChwkT_BByy",
        "outputId": "a0e1413b-1b83-4bb6-edf3-b7f7b74344f3",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# while True:\n",
        "try:\n",
        "    NER_df = pd.read_csv(\"ner.csv\")\n",
        "except FileNotFoundError:\n",
        "    import kagglehub\n",
        "    from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "    # Set the path to the file you'd like to load\n",
        "    file_path = \"ner.csv\"\n",
        "\n",
        "    # Load the latest version\n",
        "    NER_df = kagglehub.load_dataset(\n",
        "    KaggleDatasetAdapter.PANDAS,\n",
        "    \"naseralqaydeh/named-entity-recognition-ner-corpus\",\n",
        "    file_path,\n",
        "\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.600166Z",
          "iopub.status.busy": "2025-04-08T06:44:14.599922Z",
          "iopub.status.idle": "2025-04-08T06:44:14.624403Z",
          "shell.execute_reply": "2025-04-08T06:44:14.623061Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.600143Z"
        },
        "id": "pbmp-QJeBByy",
        "outputId": "65ccf3ad-6000-463d-ea83-6f7791c6ef29",
        "trusted": true
      },
      "outputs": [
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "0",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "1",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "864a1043-73ce-4e6d-81e5-6ec464f67dfd",
              "rows": [
                [
                  "Sentence #",
                  "Sentence: 1",
                  "Sentence: 2"
                ],
                [
                  "Sentence",
                  "Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .",
                  "Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \""
                ],
                [
                  "POS",
                  "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']",
                  "['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', 'VBD', 'DT', 'NNS', 'WP', 'VBD', 'NNS', 'IN', 'JJ', 'NNS', 'IN', '``', 'NNP', 'NN', 'CD', 'NN', '``', 'CC', '``', 'VB', 'DT', 'NNS', '.', '``']"
                ],
                [
                  "Tag",
                  "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']",
                  "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 4
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sentence #</th>\n",
              "      <td>Sentence: 1</td>\n",
              "      <td>Sentence: 2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Sentence</th>\n",
              "      <td>Thousands of demonstrators have marched throug...</td>\n",
              "      <td>Families of soldiers killed in the conflict jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>POS</th>\n",
              "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
              "      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tag</th>\n",
              "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
              "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                            0  \\\n",
              "Sentence #                                        Sentence: 1   \n",
              "Sentence    Thousands of demonstrators have marched throug...   \n",
              "POS         ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
              "Tag         ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...   \n",
              "\n",
              "                                                            1  \n",
              "Sentence #                                        Sentence: 2  \n",
              "Sentence    Families of soldiers killed in the conflict jo...  \n",
              "POS         ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...  \n",
              "Tag         ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(NER_df.head(2).T)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83DhBOH3BByz"
      },
      "source": [
        "Essential info about entities:\n",
        "\n",
        "- geo = Geographical Entity\n",
        "- org = Organization\n",
        "- per = Person\n",
        "- gpe = Geopolitical Entity\n",
        "- tim = Time indicator\n",
        "- art = Artifact\n",
        "- eve = Event\n",
        "- nat = Natural Phenomenon"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPUEdKJgBByz"
      },
      "source": [
        "### Class it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.625623Z",
          "iopub.status.busy": "2025-04-08T06:44:14.625361Z",
          "iopub.status.idle": "2025-04-08T06:44:14.629903Z",
          "shell.execute_reply": "2025-04-08T06:44:14.628612Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.625597Z"
        },
        "id": "MHkeijwKBByz",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class The_Neural_Net:\n",
        "    def __init__(self):\n",
        "        self.max_len = 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfdhiTYxBBy0"
      },
      "source": [
        "1. Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.631026Z",
          "iopub.status.busy": "2025-04-08T06:44:14.630740Z",
          "iopub.status.idle": "2025-04-08T06:44:14.641056Z",
          "shell.execute_reply": "2025-04-08T06:44:14.639637Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.630999Z"
        },
        "id": "CpILzdjKBBy0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def read_data(self):\n",
        "    try:\n",
        "        NER_df = pd.read_csv(\"ner.csv\")\n",
        "    except FileNotFoundError:\n",
        "        import kagglehub\n",
        "        from kagglehub import KaggleDatasetAdapter\n",
        "\n",
        "        file_path = \"ner.csv\"\n",
        "\n",
        "        NER_df = kagglehub.load_dataset(\n",
        "        KaggleDatasetAdapter.PANDAS,\n",
        "        \"naseralqaydeh/named-entity-recognition-ner-corpus\",\n",
        "        file_path,\n",
        "\n",
        "        )\n",
        "    print(NER_df.shape,\"\\n\")\n",
        "    print(\"\\n\",NER_df.info())\n",
        "    return NER_df\n",
        "The_Neural_Net.read_data = read_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP4EEJrsBBy0"
      },
      "source": [
        "2. Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.642208Z",
          "iopub.status.busy": "2025-04-08T06:44:14.641902Z",
          "iopub.status.idle": "2025-04-08T06:44:14.653336Z",
          "shell.execute_reply": "2025-04-08T06:44:14.651987Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.642174Z"
        },
        "id": "TkOkLpkyBBy1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def PreProcess(self):\n",
        "    NER_df = self.read_data()\n",
        "    NER_df.dropna(inplace=True)\n",
        "    NER_df.drop(columns=[\"Sentence #\",\"POS\"],inplace=True)\n",
        "    NER_df[\"Tag\"] = NER_df[\"Tag\"].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(NER_df[\"Sentence\"], NER_df[\"Tag\"], shuffle=True,test_size=0.20, random_state=42)\n",
        "    del NER_df\n",
        "\n",
        "    self.X_tokenizer = Tokenizer(lower=False,oov_token=\"UNK\")\n",
        "    self.X_tokenizer.fit_on_texts(self.X_train)\n",
        "\n",
        "    self.X_train = self.X_tokenizer.texts_to_sequences(self.X_train)\n",
        "    self.X_test = self.X_tokenizer.texts_to_sequences(self.X_test)\n",
        "\n",
        "    self.vocab_len = len(self.X_tokenizer.word_index)\n",
        "    print(f\"Number of unique tokens:\\t{self.vocab_len}\")\n",
        "\n",
        "    self.y_tokenizer = Tokenizer(lower=False,oov_token=\"UNK\")\n",
        "    self.y_tokenizer.fit_on_texts(self.y_train)\n",
        "\n",
        "    self.y_train = self.y_tokenizer.texts_to_sequences(self.y_train)\n",
        "    self.y_test = self.y_tokenizer.texts_to_sequences(self.y_test)\n",
        "\n",
        "    for dataset in [self.X_train,self.X_test]:\n",
        "        for i in range(len(dataset)):\n",
        "            self.max_len = max(self.max_len,len(dataset[i]))\n",
        "\n",
        "    self.X_train = pad_sequences(self.X_train, maxlen=self.max_len, padding=\"post\", value=0)\n",
        "    self.X_test = pad_sequences(self.X_test, maxlen=self.max_len, padding=\"post\", value=0)\n",
        "\n",
        "    self.y_train = pad_sequences(self.y_train, maxlen=self.max_len, padding=\"post\", value=0)\n",
        "    self.y_test = pad_sequences(self.y_test, maxlen=self.max_len, padding=\"post\", value=0)\n",
        "\n",
        "    self.Number_of_classes_K = len(self.y_tokenizer.word_index) + 1\n",
        "\n",
        "The_Neural_Net.PreProcess = PreProcess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.654421Z",
          "iopub.status.busy": "2025-04-08T06:44:14.654127Z",
          "iopub.status.idle": "2025-04-08T06:44:14.666538Z",
          "shell.execute_reply": "2025-04-08T06:44:14.665585Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.654396Z"
        },
        "id": "ikcuUmJBBBy1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def model_arch(self):\n",
        "    vector_size = 4\n",
        "\n",
        "    input_layer = Input(shape=(self.max_len,))\n",
        "    embedding_layer = Embedding(input_dim=self.vocab_len + 1, output_dim=vector_size, mask_zero=True, trainable=True)(input_layer)\n",
        "    dropout_layer_1 = Dropout(0.075)(embedding_layer)\n",
        "    bidirectional_LSTM_Layer = Bidirectional(LSTM(vector_size * 2, return_sequences=True))(dropout_layer_1)\n",
        "    # bidirectional_LSTM_Layer = Bidirectional(LSTM(vector_size * 2, return_sequences=True))(embedding_layer)\n",
        "    output_layer = Dense(self.Number_of_classes_K)(bidirectional_LSTM_Layer)\n",
        "\n",
        "    self.model = Model(input_layer, output_layer)\n",
        "    print(self.model.summary())\n",
        "\n",
        "    self.model.compile(optimizer=\"adam\",loss=SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"])\n",
        "The_Neural_Net.model_arch = model_arch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.667598Z",
          "iopub.status.busy": "2025-04-08T06:44:14.667390Z",
          "iopub.status.idle": "2025-04-08T06:44:14.680788Z",
          "shell.execute_reply": "2025-04-08T06:44:14.679744Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.667578Z"
        },
        "id": "bVM55ti6BBy1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def model_fit(self,num_of_epochs):\n",
        "    early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
        "    patience=3,          # Number of epochs with no improvement after which training will stop\n",
        "    restore_best_weights=True  # Restore the weights of the best epoch\n",
        "    )\n",
        "    self.num_of_epochs = num_of_epochs\n",
        "    self.model.fit(\n",
        "            self.X_train,\n",
        "            self.y_train,\n",
        "            epochs=num_of_epochs,\n",
        "            validation_data=(self.X_test, self.y_test),\n",
        "           callbacks=[early_stopping]  # Include EarlyStopping in callbacks\n",
        "        )\n",
        "The_Neural_Net.model_fit = model_fit\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "dGj44_ZPBynu"
      },
      "outputs": [],
      "source": [
        "def save_to_file(self):\n",
        "    with open('X_tokenizer.pkl', 'wb') as file:\n",
        "        pickle.dump(self.X_tokenizer, file)\n",
        "    print(\"X_tokenizer saved to X_tokenizer.pkl\")\n",
        "\n",
        "    with open('y_tokenizer.pkl', 'wb') as file:\n",
        "        pickle.dump(self.y_tokenizer, file)\n",
        "    print(\"y_tokenizer saved to y_tokenizer.pkl\")\n",
        "\n",
        "    model_save_path = f\"ner_model_{self.num_of_epochs}.keras\"\n",
        "    # print(model_save_path)\n",
        "    self.model.save(model_save_path)\n",
        "    print(f\"Model saved to {model_save_path}\")\n",
        "The_Neural_Net.save_to_file = save_to_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "YI_cn5TpBynu"
      },
      "outputs": [],
      "source": [
        "def load_from_file(self,num_of_epochs):\n",
        "    # self.num_of_epochs = num_of_epochs\n",
        "    with open('X_tokenizer.pkl', 'rb') as file:\n",
        "        self.X_tokenizer = pickle.load(file)\n",
        "        print(\"Tokenizer loaded from X_tokenizer.pkl\")\n",
        "\n",
        "    with open('y_tokenizer.pkl', 'rb') as file:\n",
        "        self.y_tokenizer = pickle.load(file)\n",
        "        print(\"Tokenizer loaded from y_tokenizer.pkl\")\n",
        "\n",
        "    model_save_path = f\"ner_model_{num_of_epochs}.keras\"\n",
        "    self.model = load_model(model_save_path)\n",
        "    print(f\"Model loaded from {model_save_path}\")\n",
        "\n",
        "\n",
        "The_Neural_Net.load_from_file = load_from_file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.681995Z",
          "iopub.status.busy": "2025-04-08T06:44:14.681669Z",
          "iopub.status.idle": "2025-04-08T06:44:14.692250Z",
          "shell.execute_reply": "2025-04-08T06:44:14.691223Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.681970Z"
        },
        "id": "5eIWnD-5BBy1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def predict(self,model,sentence):\n",
        "    sentence_tokens = self.X_tokenizer.texts_to_sequences([sentence])\n",
        "    # print(len(sentence.split()))\n",
        "    # print(len(sentence_tokens[0]))\n",
        "    # tokens_to_words = [word for word, index in self.X_tokenizer.word_index.items() if index in sentence_tokens[0]]\n",
        "\n",
        "    predictions = model.predict(pad_sequences(sentence_tokens,\n",
        "                                            maxlen=self.max_len,\n",
        "                                            padding=\"post\"))\n",
        "    # print(predictions)\n",
        "    prediction_ner = np.argmax(predictions,axis=-1)\n",
        "    # print(prediction_ner)\n",
        "\n",
        "    NER_tags = [self.y_tokenizer.index_word[num] for num in list(prediction_ner.flatten())]\n",
        "    final_pred = {\"Word\":[],\"Tag\":[]}\n",
        "    sentence_split = sentence.split()\n",
        "    for Word,Tag in zip(sentence_split,NER_tags):\n",
        "        # final_pred[tokens_to_words[i]] = NER_tags[i]\n",
        "        final_pred[\"Word\"].append(Word)\n",
        "        final_pred[\"Tag\"].append(Tag)\n",
        "    return pd.DataFrame(final_pred)\n",
        "The_Neural_Net.predict = predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:14.693439Z",
          "iopub.status.busy": "2025-04-08T06:44:14.693135Z",
          "iopub.status.idle": "2025-04-08T06:44:19.662284Z",
          "shell.execute_reply": "2025-04-08T06:44:19.661152Z",
          "shell.execute_reply.started": "2025-04-08T06:44:14.693414Z"
        },
        "id": "4_aarSViBBy2",
        "outputId": "074b68cd-d6ca-4e45-dddd-4673b9eaa33b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(47959, 4) \n",
            "\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 47959 entries, 0 to 47958\n",
            "Data columns (total 4 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Sentence #  47959 non-null  object\n",
            " 1   Sentence    47959 non-null  object\n",
            " 2   POS         47959 non-null  object\n",
            " 3   Tag         47959 non-null  object\n",
            "dtypes: object(4)\n",
            "memory usage: 1.5+ MB\n",
            "\n",
            " None\n",
            "Number of unique tokens:\t28761\n"
          ]
        }
      ],
      "source": [
        "NN_obj = The_Neural_Net()\n",
        "NN_obj.PreProcess()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "execution": {
          "iopub.execute_input": "2025-04-08T06:44:28.651413Z",
          "iopub.status.busy": "2025-04-08T06:44:28.651115Z",
          "iopub.status.idle": "2025-04-08T06:46:40.867517Z",
          "shell.execute_reply": "2025-04-08T06:46:40.865866Z",
          "shell.execute_reply.started": "2025-04-08T06:44:28.651387Z"
        },
        "id": "b1f3yDKaDRd6",
        "outputId": "20bab25d-3449-4b6e-d30b-aa48ea5552a1",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
            "INFO:tensorflow:Initializing the TPU system: local\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_7\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_7\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_7         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │    <span style=\"color: #00af00; text-decoration-color: #00af00\">115,048</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)     │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_10        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_7     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">832</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">323</span> │ bidirectional_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_7       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding_7         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │    \u001b[38;5;34m115,048\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m4\u001b[0m)     │          \u001b[38;5;34m0\u001b[0m │ embedding_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ not_equal_10        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer_7[\u001b[38;5;34m0\u001b[0m]… │\n",
              "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ bidirectional_7     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m16\u001b[0m)    │        \u001b[38;5;34m832\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m19\u001b[0m)    │        \u001b[38;5;34m323\u001b[0m │ bidirectional_7[\u001b[38;5;34m…\u001b[0m │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,203</span> (453.92 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m116,203\u001b[0m (453.92 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">116,203</span> (453.92 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m116,203\u001b[0m (453.92 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 59ms/step - accuracy: 0.2107 - loss: 1.2209 - val_accuracy: 0.2081 - val_loss: 0.6066\n",
            "Epoch 2/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 59ms/step - accuracy: 0.2076 - loss: 0.5887 - val_accuracy: 0.1947 - val_loss: 0.5364\n",
            "Epoch 3/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 57ms/step - accuracy: 0.1965 - loss: 0.5164 - val_accuracy: 0.1982 - val_loss: 0.4659\n",
            "Epoch 4/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 56ms/step - accuracy: 0.1996 - loss: 0.4496 - val_accuracy: 0.2009 - val_loss: 0.4220\n",
            "Epoch 5/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 56ms/step - accuracy: 0.2022 - loss: 0.4053 - val_accuracy: 0.2019 - val_loss: 0.3925\n",
            "Epoch 6/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 56ms/step - accuracy: 0.2034 - loss: 0.3759 - val_accuracy: 0.2025 - val_loss: 0.3769\n",
            "Epoch 7/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 57ms/step - accuracy: 0.2080 - loss: 0.3576 - val_accuracy: 0.2179 - val_loss: 0.3680\n",
            "Epoch 8/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 56ms/step - accuracy: 0.2201 - loss: 0.3442 - val_accuracy: 0.2182 - val_loss: 0.3632\n",
            "Epoch 9/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 66ms/step - accuracy: 0.2207 - loss: 0.3342 - val_accuracy: 0.2184 - val_loss: 0.3591\n",
            "Epoch 10/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m822s\u001b[0m 686ms/step - accuracy: 0.2211 - loss: 0.3268 - val_accuracy: 0.2188 - val_loss: 0.3571\n",
            "Epoch 11/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 60ms/step - accuracy: 0.2216 - loss: 0.3206 - val_accuracy: 0.2189 - val_loss: 0.3553\n",
            "Epoch 12/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 59ms/step - accuracy: 0.2219 - loss: 0.3148 - val_accuracy: 0.2191 - val_loss: 0.3527\n",
            "Epoch 13/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 62ms/step - accuracy: 0.2223 - loss: 0.3096 - val_accuracy: 0.2192 - val_loss: 0.3529\n",
            "Epoch 14/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 62ms/step - accuracy: 0.2227 - loss: 0.3053 - val_accuracy: 0.2194 - val_loss: 0.3516\n",
            "Epoch 15/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 66ms/step - accuracy: 0.2228 - loss: 0.3030 - val_accuracy: 0.2194 - val_loss: 0.3516\n",
            "Epoch 16/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 64ms/step - accuracy: 0.2231 - loss: 0.2986 - val_accuracy: 0.2196 - val_loss: 0.3523\n",
            "Epoch 17/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 64ms/step - accuracy: 0.2234 - loss: 0.2953 - val_accuracy: 0.2196 - val_loss: 0.3538\n",
            "Epoch 18/51\n",
            "\u001b[1m1199/1199\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 88ms/step - accuracy: 0.2237 - loss: 0.2927 - val_accuracy: 0.2197 - val_loss: 0.3519\n"
          ]
        }
      ],
      "source": [
        "num_of_epochs = 51\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local') # Detect TPU\n",
        "    tf.config.experimental_connect_to_cluster(tpu)\n",
        "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "    tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
        "\n",
        "    num_of_epochs = 100\n",
        "    with tpu_strategy.scope():\n",
        "        NN_obj.model_arch()\n",
        "        NN_obj.model_fit(num_of_epochs)\n",
        "\n",
        "except Exception as e:\n",
        "    NN_obj.model_arch()\n",
        "    NN_obj.model_fit(num_of_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:46:40.870108Z",
          "iopub.status.busy": "2025-04-08T06:46:40.869789Z",
          "iopub.status.idle": "2025-04-08T06:46:40.874844Z",
          "shell.execute_reply": "2025-04-08T06:46:40.873621Z",
          "shell.execute_reply.started": "2025-04-08T06:46:40.870078Z"
        },
        "id": "-gP2rBVgBBy2",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# num_of_epochs = 5\n",
        "# if tf.test.is_gpu_available():\n",
        "#     num_of_epochs = 100\n",
        "#     with tf.device('/device:GPU:0'):\n",
        "#         NN_obj.model_fit(num_of_epochs)\n",
        "# else:\n",
        "#     NN_obj.model_fit(num_of_epochs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "5myd2XyuCXEw"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_tokenizer saved to X_tokenizer.pkl\n",
            "y_tokenizer saved to y_tokenizer.pkl\n",
            "Model saved to ner_model_51.keras\n"
          ]
        }
      ],
      "source": [
        "NN_obj.save_to_file()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "iItmWwcOBynv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tokenizer loaded from X_tokenizer.pkl\n",
            "Tokenizer loaded from y_tokenizer.pkl\n",
            "Model loaded from ner_model_51.keras\n"
          ]
        }
      ],
      "source": [
        "NN_obj.load_from_file(num_of_epochs=num_of_epochs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-04-08T06:46:40.876082Z",
          "iopub.status.busy": "2025-04-08T06:46:40.875803Z",
          "iopub.status.idle": "2025-04-08T06:46:43.265881Z",
          "shell.execute_reply": "2025-04-08T06:46:43.264566Z",
          "shell.execute_reply.started": "2025-04-08T06:46:40.876056Z"
        },
        "id": "ON0FZkoaBBy2",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Word",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Tag",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "0af1b895-615c-44d6-9c10-4b3361d7e6ea",
              "rows": [
                [
                  "0",
                  "Is",
                  "O"
                ],
                [
                  "1",
                  "this",
                  "O"
                ],
                [
                  "2",
                  "the",
                  "O"
                ],
                [
                  "3",
                  "real",
                  "O"
                ],
                [
                  "4",
                  "life?",
                  "O"
                ],
                [
                  "5",
                  "Is",
                  "O"
                ],
                [
                  "6",
                  "this",
                  "O"
                ],
                [
                  "7",
                  "just",
                  "O"
                ],
                [
                  "8",
                  "fantasy?",
                  "O"
                ],
                [
                  "9",
                  "Caught",
                  "O"
                ],
                [
                  "10",
                  "in",
                  "O"
                ],
                [
                  "11",
                  "a",
                  "O"
                ],
                [
                  "12",
                  "landslide,",
                  "O"
                ],
                [
                  "13",
                  "no",
                  "O"
                ],
                [
                  "14",
                  "escape",
                  "O"
                ],
                [
                  "15",
                  "from",
                  "O"
                ],
                [
                  "16",
                  "reality",
                  "O"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 17
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Is</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>this</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>real</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>life?</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Is</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>this</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>just</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>fantasy?</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Caught</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>in</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>a</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>landslide,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>no</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>escape</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>from</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>reality</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          Word Tag\n",
              "0           Is   O\n",
              "1         this   O\n",
              "2          the   O\n",
              "3         real   O\n",
              "4        life?   O\n",
              "5           Is   O\n",
              "6         this   O\n",
              "7         just   O\n",
              "8     fantasy?   O\n",
              "9       Caught   O\n",
              "10          in   O\n",
              "11           a   O\n",
              "12  landslide,   O\n",
              "13          no   O\n",
              "14      escape   O\n",
              "15        from   O\n",
              "16     reality   O"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentence = \"\"\"Is this the real life? Is this just fantasy? Caught in a landslide, no escape from reality\"\"\"\n",
        "model = NN_obj.model\n",
        "prediction_df = NN_obj.predict(model=NN_obj.model,sentence=sentence)\n",
        "display(prediction_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Word",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Tag",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "8e8a412f-2bef-470b-a3ae-200dc70db87f",
              "rows": [
                [
                  "0",
                  "Apoorv",
                  "B-org"
                ],
                [
                  "1",
                  "Code,",
                  "B-org"
                ],
                [
                  "2",
                  "Ankur",
                  "O"
                ],
                [
                  "3",
                  "question",
                  "O"
                ],
                [
                  "4",
                  "one,",
                  "O"
                ],
                [
                  "5",
                  "Alok,",
                  "O"
                ],
                [
                  "6",
                  "zoom",
                  "O"
                ],
                [
                  "7",
                  "meeting",
                  "O"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 8
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apoorv</td>\n",
              "      <td>B-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Code,</td>\n",
              "      <td>B-org</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ankur</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>question</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Alok,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zoom</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>meeting</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Word    Tag\n",
              "0    Apoorv  B-org\n",
              "1     Code,  B-org\n",
              "2     Ankur      O\n",
              "3  question      O\n",
              "4      one,      O\n",
              "5     Alok,      O\n",
              "6      zoom      O\n",
              "7   meeting      O"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentence = \"\"\"Apoorv Code, Ankur question one, Alok, zoom meeting\"\"\"\n",
        "model = NN_obj.model\n",
        "prediction_df = NN_obj.predict(model=NN_obj.model,sentence=sentence)\n",
        "display(prediction_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "b5n-hXZtBynv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step\n"
          ]
        },
        {
          "data": {
            "application/vnd.microsoft.datawrangler.viewer.v0+json": {
              "columns": [
                {
                  "name": "index",
                  "rawType": "int64",
                  "type": "integer"
                },
                {
                  "name": "Word",
                  "rawType": "object",
                  "type": "string"
                },
                {
                  "name": "Tag",
                  "rawType": "object",
                  "type": "string"
                }
              ],
              "conversionMethod": "pd.DataFrame",
              "ref": "28b8edae-fd3d-4ac8-a36b-49fac6831c3d",
              "rows": [
                [
                  "0",
                  "Apoorv",
                  "B-per"
                ],
                [
                  "1",
                  "Code,",
                  "B-per"
                ],
                [
                  "2",
                  "Ankur",
                  "O"
                ],
                [
                  "3",
                  "question",
                  "O"
                ],
                [
                  "4",
                  "one,",
                  "O"
                ],
                [
                  "5",
                  "Alok,",
                  "O"
                ],
                [
                  "6",
                  "zoom",
                  "O"
                ],
                [
                  "7",
                  "meeting",
                  "O"
                ]
              ],
              "shape": {
                "columns": 2,
                "rows": 8
              }
            },
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Word</th>\n",
              "      <th>Tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Apoorv</td>\n",
              "      <td>B-per</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Code,</td>\n",
              "      <td>B-per</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ankur</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>question</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>one,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Alok,</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>zoom</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>meeting</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Word    Tag\n",
              "0    Apoorv  B-per\n",
              "1     Code,  B-per\n",
              "2     Ankur      O\n",
              "3  question      O\n",
              "4      one,      O\n",
              "5     Alok,      O\n",
              "6      zoom      O\n",
              "7   meeting      O"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentence = \"\"\"Apoorv Code, Ankur question one, Alok, zoom meeting\"\"\"\n",
        "model = NN_obj.model\n",
        "prediction_df = NN_obj.predict(model=NN_obj.model,sentence=sentence)\n",
        "display(prediction_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kaggle": {
      "accelerator": "tpu1vmV38",
      "dataSources": [
        {
          "databundleVersionId": 3092179,
          "datasetId": 1861688,
          "sourceId": 3043695,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30920,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
