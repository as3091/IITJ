{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/as3091/IITJ/blob/NER/ML/Assign_2/NER/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LJz_m8KBByu"
   },
   "source": [
    "Title: Named Entity Recognition\n",
    "\n",
    "Description:\n",
    "In this NER-focused project, you will design and develop a custom Named Entity Recognition (NER) system for text analysis. Named Entity Recognition involves identifying and classifying specific entities, such as names, dates, locations, and more, within unstructured text data. Your project will offer a versatile NER solution that will work well on the provided dataset.\n",
    "\n",
    "Dataset: Named Entity Recognition (NER) Corpus (kaggle.com)\n",
    "\n",
    "https://www.kaggle.com/datasets/naseralqaydeh/named-entity-recognition-ner-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:43:27.954258Z",
     "iopub.status.busy": "2025-04-08T06:43:27.954071Z",
     "iopub.status.idle": "2025-04-08T06:43:36.402523Z",
     "shell.execute_reply": "2025-04-08T06:43:36.401044Z",
     "shell.execute_reply.started": "2025-04-08T06:43:27.954237Z"
    },
    "id": "sIOfipnGBByw",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow --quiet\n",
    "# !pip install keras --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:43:36.403769Z",
     "iopub.status.busy": "2025-04-08T06:43:36.403514Z",
     "iopub.status.idle": "2025-04-08T06:43:58.766901Z",
     "shell.execute_reply": "2025-04-08T06:43:58.766018Z",
     "shell.execute_reply.started": "2025-04-08T06:43:36.403742Z"
    },
    "id": "5YUItkm-BByx",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:28:57.957070: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-09 16:28:57.957766: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 16:28:57.961868: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-04-09 16:28:57.985054: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744216138.011549   18093 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744216138.020729   18093 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1744216138.045993   18093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744216138.046040   18093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744216138.046042   18093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1744216138.046044   18093 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-09 16:28:58.050815: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import warnings,sys, ast, pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from IPython.display import display, HTML\n",
    "# import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.layers import Dense, Input, Bidirectional, LSTM, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "# from keras.random import SeedGenerator\n",
    "\n",
    "# seed_gen = SeedGenerator(seed=42)\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:43:58.770499Z",
     "iopub.status.busy": "2025-04-08T06:43:58.770237Z",
     "iopub.status.idle": "2025-04-08T06:44:02.246367Z",
     "shell.execute_reply": "2025-04-08T06:44:02.244933Z",
     "shell.execute_reply.started": "2025-04-08T06:43:58.770475Z"
    },
    "id": "XlhvMq8SBByy",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# !pip install kagglehub --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:02.247993Z",
     "iopub.status.busy": "2025-04-08T06:44:02.247702Z",
     "iopub.status.idle": "2025-04-08T06:44:14.598820Z",
     "shell.execute_reply": "2025-04-08T06:44:14.598058Z",
     "shell.execute_reply.started": "2025-04-08T06:44:02.247964Z"
    },
    "id": "gqChwkT_BByy",
    "outputId": "7ec3f9d8-a441-46cc-b756-0bee44ff7d0c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# while True:\n",
    "try:\n",
    "    NER_df = pd.read_csv(\"ner.csv\")\n",
    "except FileNotFoundError:\n",
    "    import kagglehub\n",
    "    from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "    # Set the path to the file you'd like to load\n",
    "    file_path = \"ner.csv\"\n",
    "\n",
    "    # Load the latest version\n",
    "    NER_df = kagglehub.load_dataset(\n",
    "    KaggleDatasetAdapter.PANDAS,\n",
    "    \"naseralqaydeh/named-entity-recognition-ner-corpus\",\n",
    "    file_path,\n",
    "\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.600166Z",
     "iopub.status.busy": "2025-04-08T06:44:14.599922Z",
     "iopub.status.idle": "2025-04-08T06:44:14.624403Z",
     "shell.execute_reply": "2025-04-08T06:44:14.623061Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.600143Z"
    },
    "id": "pbmp-QJeBByy",
    "outputId": "8ddc1bca-f590-4538-ee1e-30402ff721f3",
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "1",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "7e881640-9f88-4bce-ac50-bd8ef0663daf",
       "rows": [
        [
         "Sentence #",
         "Sentence: 1",
         "Sentence: 2"
        ],
        [
         "Sentence",
         "Thousands of demonstrators have marched through London to protest the war in Iraq and demand the withdrawal of British troops from that country .",
         "Families of soldiers killed in the conflict joined the protesters who carried banners with such slogans as \" Bush Number One Terrorist \" and \" Stop the Bombings . \""
        ],
        [
         "POS",
         "['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP', 'TO', 'VB', 'DT', 'NN', 'IN', 'NNP', 'CC', 'VB', 'DT', 'NN', 'IN', 'JJ', 'NNS', 'IN', 'DT', 'NN', '.']",
         "['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', 'VBD', 'DT', 'NNS', 'WP', 'VBD', 'NNS', 'IN', 'JJ', 'NNS', 'IN', '``', 'NNP', 'NN', 'CD', 'NN', '``', 'CC', '``', 'VB', 'DT', 'NNS', '.', '``']"
        ],
        [
         "Tag",
         "['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', 'O', 'O', 'O', 'O', 'B-gpe', 'O', 'O', 'O', 'O', 'O']",
         "['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-per', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 4
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sentence #</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Sentence: 2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sentence</th>\n",
       "      <td>Thousands of demonstrators have marched throug...</td>\n",
       "      <td>Families of soldiers killed in the conflict jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>POS</th>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...</td>\n",
       "      <td>['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tag</th>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...</td>\n",
       "      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            0  \\\n",
       "Sentence #                                        Sentence: 1   \n",
       "Sentence    Thousands of demonstrators have marched throug...   \n",
       "POS         ['NNS', 'IN', 'NNS', 'VBP', 'VBN', 'IN', 'NNP'...   \n",
       "Tag         ['O', 'O', 'O', 'O', 'O', 'O', 'B-geo', 'O', '...   \n",
       "\n",
       "                                                            1  \n",
       "Sentence #                                        Sentence: 2  \n",
       "Sentence    Families of soldiers killed in the conflict jo...  \n",
       "POS         ['NNS', 'IN', 'NNS', 'VBN', 'IN', 'DT', 'NN', ...  \n",
       "Tag         ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(NER_df.head(2).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "83DhBOH3BByz"
   },
   "source": [
    "Essential info about entities:\n",
    "\n",
    "- geo = Geographical Entity\n",
    "- org = Organization\n",
    "- per = Person\n",
    "- gpe = Geopolitical Entity\n",
    "- tim = Time indicator\n",
    "- art = Artifact\n",
    "- eve = Event\n",
    "- nat = Natural Phenomenon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VPUEdKJgBByz"
   },
   "source": [
    "### Class it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.625623Z",
     "iopub.status.busy": "2025-04-08T06:44:14.625361Z",
     "iopub.status.idle": "2025-04-08T06:44:14.629903Z",
     "shell.execute_reply": "2025-04-08T06:44:14.628612Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.625597Z"
    },
    "id": "MHkeijwKBByz",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class The_Neural_Net:\n",
    "    def __init__(self):\n",
    "        self.max_len = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfdhiTYxBBy0"
   },
   "source": [
    "1. Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.631026Z",
     "iopub.status.busy": "2025-04-08T06:44:14.630740Z",
     "iopub.status.idle": "2025-04-08T06:44:14.641056Z",
     "shell.execute_reply": "2025-04-08T06:44:14.639637Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.630999Z"
    },
    "id": "CpILzdjKBBy0",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def read_data(self):\n",
    "    try:\n",
    "        NER_df = pd.read_csv(\"ner.csv\")\n",
    "    except FileNotFoundError:\n",
    "        import kagglehub\n",
    "        from kagglehub import KaggleDatasetAdapter\n",
    "\n",
    "        file_path = \"ner.csv\"\n",
    "\n",
    "        NER_df = kagglehub.load_dataset(\n",
    "        KaggleDatasetAdapter.PANDAS,\n",
    "        \"naseralqaydeh/named-entity-recognition-ner-corpus\",\n",
    "        file_path,\n",
    "\n",
    "        )\n",
    "    print(NER_df.shape,\"\\n\")\n",
    "    print(\"\\n\",NER_df.info())\n",
    "    return NER_df\n",
    "The_Neural_Net.read_data = read_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kP4EEJrsBBy0"
   },
   "source": [
    "2. Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.642208Z",
     "iopub.status.busy": "2025-04-08T06:44:14.641902Z",
     "iopub.status.idle": "2025-04-08T06:44:14.653336Z",
     "shell.execute_reply": "2025-04-08T06:44:14.651987Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.642174Z"
    },
    "id": "TkOkLpkyBBy1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def PreProcess(self):\n",
    "    NER_df = self.read_data()\n",
    "    NER_df.dropna(inplace=True)\n",
    "    NER_df.drop(columns=[\"Sentence #\",\"POS\"],inplace=True)\n",
    "    NER_df[\"Tag\"] = NER_df[\"Tag\"].apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "    self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(NER_df[\"Sentence\"], NER_df[\"Tag\"], shuffle=True,test_size=0.20, random_state=42)\n",
    "    del NER_df\n",
    "\n",
    "    self.X_tokenizer = Tokenizer(lower=False,oov_token=\"UNK\")\n",
    "    self.X_tokenizer.fit_on_texts(self.X_train)\n",
    "\n",
    "    self.X_train = self.X_tokenizer.texts_to_sequences(self.X_train)\n",
    "    self.X_test = self.X_tokenizer.texts_to_sequences(self.X_test)\n",
    "\n",
    "    self.vocab_len = len(self.X_tokenizer.word_index)\n",
    "    print(f\"Number of unique tokens:\\t{self.vocab_len}\")\n",
    "\n",
    "    self.y_tokenizer = Tokenizer(lower=False,oov_token=\"UNK\")\n",
    "    self.y_tokenizer.fit_on_texts(self.y_train)\n",
    "\n",
    "    self.y_train = self.y_tokenizer.texts_to_sequences(self.y_train)\n",
    "    self.y_test = self.y_tokenizer.texts_to_sequences(self.y_test)\n",
    "\n",
    "    for dataset in [self.X_train,self.X_test]:\n",
    "        for i in range(len(dataset)):\n",
    "            self.max_len = max(self.max_len,len(dataset[i]))\n",
    "\n",
    "    self.X_train = pad_sequences(self.X_train, maxlen=self.max_len, padding=\"post\", value=0)\n",
    "    self.X_test = pad_sequences(self.X_test, maxlen=self.max_len, padding=\"post\", value=0)\n",
    "\n",
    "    self.y_train = pad_sequences(self.y_train, maxlen=self.max_len, padding=\"post\", value=0)\n",
    "    self.y_test = pad_sequences(self.y_test, maxlen=self.max_len, padding=\"post\", value=0)\n",
    "\n",
    "    self.Number_of_classes_K = len(self.y_tokenizer.word_index) + 1\n",
    "\n",
    "The_Neural_Net.PreProcess = PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.654421Z",
     "iopub.status.busy": "2025-04-08T06:44:14.654127Z",
     "iopub.status.idle": "2025-04-08T06:44:14.666538Z",
     "shell.execute_reply": "2025-04-08T06:44:14.665585Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.654396Z"
    },
    "id": "ikcuUmJBBBy1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_arch(self):\n",
    "    vector_size = 64\n",
    "\n",
    "    input_layer = Input(shape=(self.max_len,))\n",
    "    embedding_layer = Embedding(input_dim=self.vocab_len + 1, output_dim=vector_size, mask_zero=True, trainable=True)(input_layer)\n",
    "    dropout_layer_1 = Dropout(0.2)(embedding_layer)\n",
    "    bidirectional_LSTM_Layer = Bidirectional(LSTM(vector_size * 2, return_sequences=True))(dropout_layer_1)\n",
    "    output_layer = Dense(self.Number_of_classes_K)(bidirectional_LSTM_Layer)\n",
    "\n",
    "    self.model = Model(input_layer, output_layer)\n",
    "    print(self.model.summary())\n",
    "\n",
    "    self.model.compile(optimizer=\"adam\",loss=SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"])\n",
    "The_Neural_Net.model_arch = model_arch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.667598Z",
     "iopub.status.busy": "2025-04-08T06:44:14.667390Z",
     "iopub.status.idle": "2025-04-08T06:44:14.680788Z",
     "shell.execute_reply": "2025-04-08T06:44:14.679744Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.667578Z"
    },
    "id": "bVM55ti6BBy1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def model_fit(self,num_of_epochs):\n",
    "    early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
    "    patience=3,          # Number of epochs with no improvement after which training will stop\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    "    )\n",
    "\n",
    "    self.model.fit(\n",
    "            self.X_train,\n",
    "            self.y_train,\n",
    "            epochs=num_of_epochs,\n",
    "            validation_data=(self.X_test, self.y_test),\n",
    "            callbacks=[early_stopping]  # Include EarlyStopping in callbacks\n",
    "        )\n",
    "The_Neural_Net.model_fit = model_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(self):\n",
    "    with open('X_tokenizer.pkl', 'wb') as file:\n",
    "        pickle.dump(self.X_tokenizer, file)\n",
    "    print(\"X_tokenizer saved to X_tokenizer.pkl\")\n",
    "\n",
    "    with open('y_tokenizer.pkl', 'wb') as file:\n",
    "        pickle.dump(self.y_tokenizer, file)\n",
    "    print(\"y_tokenizer saved to y_tokenizer.pkl\")\n",
    "\n",
    "    model_save_path = f\"ner_model_{self.num_of_epochs}.keras\"\n",
    "    # print(model_save_path)\n",
    "    self.model.save(model_save_path)\n",
    "    print(f\"Model saved to {model_save_path}\")\n",
    "The_Neural_Net.save_to_file = save_to_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_file(self,num_of_epochs):\n",
    "    # self.num_of_epochs = num_of_epochs\n",
    "    with open('X_tokenizer.pkl', 'rb') as file:\n",
    "        self.X_tokenizer = pickle.load(file)\n",
    "        print(\"Tokenizer loaded from X_tokenizer.pkl\")\n",
    "\n",
    "    with open('y_tokenizer.pkl', 'rb') as file:\n",
    "        self.y_tokenizer = pickle.load(file)\n",
    "        print(\"Tokenizer loaded from y_tokenizer.pkl\")\n",
    "\n",
    "    model_save_path = f\"ner_model_{num_of_epochs}.keras\"\n",
    "    self.model = load_model(model_save_path)\n",
    "    print(f\"Model loaded from {model_save_path}\")\n",
    "\n",
    "    \n",
    "The_Neural_Net.load_from_file = load_from_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.681995Z",
     "iopub.status.busy": "2025-04-08T06:44:14.681669Z",
     "iopub.status.idle": "2025-04-08T06:44:14.692250Z",
     "shell.execute_reply": "2025-04-08T06:44:14.691223Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.681970Z"
    },
    "id": "5eIWnD-5BBy1",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def predict(self,model,sentence):\n",
    "    sentence_tokens = self.X_tokenizer.texts_to_sequences([sentence])\n",
    "    # print(len(sentence.split()))\n",
    "    # print(len(sentence_tokens[0]))\n",
    "    # tokens_to_words = [word for word, index in self.X_tokenizer.word_index.items() if index in sentence_tokens[0]]\n",
    "\n",
    "    predictions = model.predict(pad_sequences(sentence_tokens,\n",
    "                                            maxlen=self.max_len,\n",
    "                                            padding=\"post\"))\n",
    "    # print(predictions)\n",
    "    prediction_ner = np.argmax(predictions,axis=-1)\n",
    "    # print(prediction_ner)\n",
    "\n",
    "    NER_tags = [self.y_tokenizer.index_word[num] for num in list(prediction_ner.flatten())]\n",
    "    final_pred = {\"Word\":[],\"Tag\":[]}\n",
    "    sentence_split = sentence.split()\n",
    "    for Word,Tag in zip(sentence_split,NER_tags):\n",
    "        # final_pred[tokens_to_words[i]] = NER_tags[i]\n",
    "        final_pred[\"Word\"].append(Word)\n",
    "        final_pred[\"Tag\"].append(Tag)\n",
    "    return pd.DataFrame(final_pred)\n",
    "The_Neural_Net.predict = predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:14.693439Z",
     "iopub.status.busy": "2025-04-08T06:44:14.693135Z",
     "iopub.status.idle": "2025-04-08T06:44:19.662284Z",
     "shell.execute_reply": "2025-04-08T06:44:19.661152Z",
     "shell.execute_reply.started": "2025-04-08T06:44:14.693414Z"
    },
    "id": "4_aarSViBBy2",
    "outputId": "69fe6698-443d-4e88-eefb-b1e27d5e6c25",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(47959, 4) \n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 47959 entries, 0 to 47958\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Sentence #  47959 non-null  object\n",
      " 1   Sentence    47959 non-null  object\n",
      " 2   POS         47959 non-null  object\n",
      " 3   Tag         47959 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 1.5+ MB\n",
      "\n",
      " None\n",
      "Number of unique tokens:\t28761\n"
     ]
    }
   ],
   "source": [
    "NN_obj = The_Neural_Net()\n",
    "NN_obj.PreProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 818
    },
    "execution": {
     "iopub.execute_input": "2025-04-08T06:44:28.651413Z",
     "iopub.status.busy": "2025-04-08T06:44:28.651115Z",
     "iopub.status.idle": "2025-04-08T06:46:40.867517Z",
     "shell.execute_reply": "2025-04-08T06:46:40.865866Z",
     "shell.execute_reply.started": "2025-04-08T06:44:28.651387Z"
    },
    "id": "b1f3yDKaDRd6",
    "outputId": "15727703-4f1c-43f5-a5a7-ae6623defa8a",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Deallocate tpu buffers before initializing tpu system.\n",
      "INFO:tensorflow:Initializing the TPU system: local\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,840,768</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ input_layer[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">197,632</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">89</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">19</span>)    │      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,883</span> │ bidirectional[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │  \u001b[38;5;34m1,840,768\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m64\u001b[0m)    │          \u001b[38;5;34m0\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ input_layer[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ bidirectional       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m197,632\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m89\u001b[0m, \u001b[38;5;34m19\u001b[0m)    │      \u001b[38;5;34m4,883\u001b[0m │ bidirectional[\u001b[38;5;34m0\u001b[0m]… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,043,283</span> (7.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,043,283\u001b[0m (7.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,043,283</span> (7.79 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,043,283\u001b[0m (7.79 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:34:25.593221: E tensorflow/core/util/util.cc:131] oneDNN supports DT_BOOL only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m 122/1199\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:16\u001b[0m 183ms/step - accuracy: 0.2339 - loss: 1.5126"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/tpu/tpu_strategy_util.py:139\u001b[0m, in \u001b[0;36minitialize_tpu_system_impl\u001b[0;34m(cluster_resolver, tpu_cluster_resolver_cls)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mdevice(tpu\u001b[38;5;241m.\u001b[39m_tpu_system_device_name(job)):  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m   output \u001b[38;5;241m=\u001b[39m \u001b[43m_tpu_init_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    140\u001b[0m context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [is_global_init=false, enable_whole_mesh_compilations=false, compilation_failure_closes_chips=false, embedding_config=\"\", tpu_embedding_config=\"\", tpu_cancellation_closes_chips=2]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 5\u001b[0m\n\u001b[1;32m      4\u001b[0m tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mexperimental_connect_to_cluster(tpu)\n\u001b[0;32m----> 5\u001b[0m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtpu\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperimental\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_tpu_system\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtpu\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m tpu_strategy \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mTPUStrategy(tpu)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/distribute/cluster_resolver/tpu/tpu_cluster_resolver.py:72\u001b[0m, in \u001b[0;36minitialize_tpu_system\u001b[0;34m(cluster_resolver)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Initialize the TPU devices.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m  NotFoundError: If no TPU devices found in eager mode.\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtpu_strategy_util\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize_tpu_system_impl\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcluster_resolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTPUClusterResolver\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/tpu/tpu_strategy_util.py:142\u001b[0m, in \u001b[0;36minitialize_tpu_system_impl\u001b[0;34m(cluster_resolver, tpu_cluster_resolver_cls)\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mInvalidArgumentError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 142\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mNotFoundError(\n\u001b[1;32m    143\u001b[0m       \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    144\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTPUs not found in the cluster. Failed in initialization: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m       \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(e))\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;31mNotFoundError\u001b[0m: TPUs not found in the cluster. Failed in initialization: No OpKernel was registered to support Op 'ConfigureDistributedTPU' used by {{node ConfigureDistributedTPU}} with these attrs: [is_global_init=false, enable_whole_mesh_compilations=false, compilation_failure_closes_chips=false, embedding_config=\"\", tpu_embedding_config=\"\", tpu_cancellation_closes_chips=2]\nRegistered devices: [CPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[ConfigureDistributedTPU]] [Op:__inference__tpu_init_fn_4]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     14\u001b[0m     NN_obj\u001b[38;5;241m.\u001b[39mmodel_arch()\n\u001b[0;32m---> 15\u001b[0m     \u001b[43mNN_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_of_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mmodel_fit\u001b[0;34m(self, num_of_epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m,num_of_epochs):\n\u001b[1;32m      2\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m      3\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Metric to monitor (e.g., validation loss)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,          \u001b[38;5;66;03m# Number of epochs with no improvement after which training will stop\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Restore the weights of the best epoch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m            \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_of_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m            \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Include EarlyStopping in callbacks\u001b[39;49;00m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[1;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[1;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[1;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[1;32m    218\u001b[0m     ):\n\u001b[0;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[1;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m     args,\n\u001b[1;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1326\u001b[0m     executing_eagerly)\n\u001b[1;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1703\u001b[0m   )\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_of_epochs = 5\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='local') # Detect TPU\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.TPUStrategy(tpu)\n",
    "\n",
    "    num_of_epochs = 100\n",
    "    with tpu_strategy.scope():\n",
    "        NN_obj.model_arch()\n",
    "        NN_obj.model_fit(num_of_epochs)\n",
    "\n",
    "except Exception as e:\n",
    "    NN_obj.model_arch()\n",
    "    NN_obj.model_fit(num_of_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "execution": {
     "iopub.execute_input": "2025-04-08T06:46:40.870108Z",
     "iopub.status.busy": "2025-04-08T06:46:40.869789Z",
     "iopub.status.idle": "2025-04-08T06:46:40.874844Z",
     "shell.execute_reply": "2025-04-08T06:46:40.873621Z",
     "shell.execute_reply.started": "2025-04-08T06:46:40.870078Z"
    },
    "id": "-gP2rBVgBBy2",
    "outputId": "2e5c9f3b-3a05-41e6-ebfc-e25707b02969",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /tmp/ipykernel_18093/1298127295.py:2: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.config.list_physical_devices('GPU')` instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 16:34:08.944917: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'The_Neural_Net' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m         NN_obj\u001b[38;5;241m.\u001b[39mmodel_fit(num_of_epochs)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m----> 7\u001b[0m     \u001b[43mNN_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_of_epochs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[10], line 8\u001b[0m, in \u001b[0;36mmodel_fit\u001b[0;34m(self, num_of_epochs)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmodel_fit\u001b[39m(\u001b[38;5;28mself\u001b[39m,num_of_epochs):\n\u001b[1;32m      2\u001b[0m     early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(\n\u001b[1;32m      3\u001b[0m     monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Metric to monitor (e.g., validation loss)\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,          \u001b[38;5;66;03m# Number of epochs with no improvement after which training will stop\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# Restore the weights of the best epoch\u001b[39;00m\n\u001b[1;32m      6\u001b[0m     )\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      9\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_train,\n\u001b[1;32m     10\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train,\n\u001b[1;32m     11\u001b[0m             epochs\u001b[38;5;241m=\u001b[39mnum_of_epochs,\n\u001b[1;32m     12\u001b[0m             validation_data\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test),\n\u001b[1;32m     13\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39m[early_stopping]  \u001b[38;5;66;03m# Include EarlyStopping in callbacks\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'The_Neural_Net' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "# num_of_epochs = 5\n",
    "# if tf.test.is_gpu_available():\n",
    "#     num_of_epochs = 100\n",
    "#     with tf.device('/device:GPU:0'):\n",
    "#         NN_obj.model_fit(num_of_epochs)\n",
    "# else:\n",
    "#     NN_obj.model_fit(num_of_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from X_tokenizer.pkl\n",
      "Tokenizer loaded from y_tokenizer.pkl\n",
      "Model loaded from ner_model_5.keras\n"
     ]
    }
   ],
   "source": [
    "# NN_obj.save_to_file()\n",
    "NN_obj.load_from_file(num_of_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:46:40.876082Z",
     "iopub.status.busy": "2025-04-08T06:46:40.875803Z",
     "iopub.status.idle": "2025-04-08T06:46:43.265881Z",
     "shell.execute_reply": "2025-04-08T06:46:43.264566Z",
     "shell.execute_reply.started": "2025-04-08T06:46:40.876056Z"
    },
    "id": "ON0FZkoaBBy2",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tag",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1ce591c9-5969-41f2-88ea-ec5e66d67312",
       "rows": [
        [
         "0",
         "Is",
         "O"
        ],
        [
         "1",
         "this",
         "O"
        ],
        [
         "2",
         "the",
         "O"
        ],
        [
         "3",
         "real",
         "O"
        ],
        [
         "4",
         "life?",
         "O"
        ],
        [
         "5",
         "Is",
         "O"
        ],
        [
         "6",
         "this",
         "O"
        ],
        [
         "7",
         "just",
         "O"
        ],
        [
         "8",
         "fantasy?",
         "O"
        ],
        [
         "9",
         "Caught",
         "O"
        ],
        [
         "10",
         "in",
         "O"
        ],
        [
         "11",
         "a",
         "O"
        ],
        [
         "12",
         "landslide,",
         "O"
        ],
        [
         "13",
         "no",
         "O"
        ],
        [
         "14",
         "escape",
         "O"
        ],
        [
         "15",
         "from",
         "O"
        ],
        [
         "16",
         "reality",
         "O"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 17
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Is</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>this</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>real</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>life?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Is</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>this</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>just</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>fantasy?</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Caught</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>a</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>landslide,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>no</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>escape</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>from</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>reality</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word Tag\n",
       "0           Is   O\n",
       "1         this   O\n",
       "2          the   O\n",
       "3         real   O\n",
       "4        life?   O\n",
       "5           Is   O\n",
       "6         this   O\n",
       "7         just   O\n",
       "8     fantasy?   O\n",
       "9       Caught   O\n",
       "10          in   O\n",
       "11           a   O\n",
       "12  landslide,   O\n",
       "13          no   O\n",
       "14      escape   O\n",
       "15        from   O\n",
       "16     reality   O"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = \"\"\"Is this the real life? Is this just fantasy? Caught in a landslide, no escape from reality\"\"\"\n",
    "model = NN_obj.model\n",
    "prediction_df = NN_obj.predict(model=NN_obj.model,sentence=sentence)\n",
    "display(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Word",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Tag",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "f51fd1c0-2c61-4125-aa2a-2b9ad0b5efb1",
       "rows": [
        [
         "0",
         "Apoorv",
         "O"
        ],
        [
         "1",
         "Code,",
         "O"
        ],
        [
         "2",
         "Ankur",
         "O"
        ],
        [
         "3",
         "question",
         "O"
        ],
        [
         "4",
         "one,",
         "O"
        ],
        [
         "5",
         "Alok,",
         "O"
        ],
        [
         "6",
         "zoom",
         "O"
        ],
        [
         "7",
         "meeting",
         "O"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 8
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Apoorv</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Code,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ankur</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>question</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>one,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Alok,</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zoom</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>meeting</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word Tag\n",
       "0    Apoorv   O\n",
       "1     Code,   O\n",
       "2     Ankur   O\n",
       "3  question   O\n",
       "4      one,   O\n",
       "5     Alok,   O\n",
       "6      zoom   O\n",
       "7   meeting   O"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence = \"\"\"Apoorv Code, Ankur question one, Alok, zoom meeting\"\"\"\n",
    "model = NN_obj.model\n",
    "prediction_df = NN_obj.predict(model=NN_obj.model,sentence=sentence)\n",
    "display(prediction_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rough work below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:46:43.267624Z",
     "iopub.status.busy": "2025-04-08T06:46:43.267319Z",
     "iopub.status.idle": "2025-04-08T06:46:43.437310Z",
     "shell.execute_reply": "2025-04-08T06:46:43.436248Z",
     "shell.execute_reply.started": "2025-04-08T06:46:43.267594Z"
    },
    "id": "Rv0pyTx-BBy3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "# dt_now = dt.datetime.now().strftime(\"%y%m%d_%H%M\")\n",
    "model_save_path = f\"ner_model_{num_of_epochs}.keras\"  # You can specify any file path\n",
    "# print(model_save_path)\n",
    "NN_obj.model.save(model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-08T06:46:43.438288Z",
     "iopub.status.busy": "2025-04-08T06:46:43.438046Z",
     "iopub.status.idle": "2025-04-08T06:46:44.093317Z",
     "shell.execute_reply": "2025-04-08T06:46:44.091901Z",
     "shell.execute_reply.started": "2025-04-08T06:46:43.438265Z"
    },
    "id": "6Gov5DK4BBy3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "loaded_model = load_model(model_save_path)\n",
    "\n",
    "sentence = \"\"\"Is this the real life? Is this just fantasy? Caught in a landslide, no escape from reality\"\"\"\n",
    "\n",
    "prediction_df = NN_obj.predict(model=loaded_model,sentence=sentence)\n",
    "display(prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Bd68hW2BBy3"
   },
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1RHYZpalBBy3"
   },
   "source": [
    "# Rough work below this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3fvgBG8uBBy3"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "loaded_model = load_model(model_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u3nTxw0aBBy4"
   },
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34xWLQ2xBBy4"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(10,))\n",
    "dense_layer = Dense(32, activation='relu')(input_layer)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkjVEHkJBBy4"
   },
   "source": [
    "3. Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f95uYthSBBy4"
   },
   "outputs": [],
   "source": [
    "def Tokenize(self):\n",
    "\n",
    "\n",
    "\n",
    "The_Neural_Net.PreProcess = PreProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fl71PhTjBBy5"
   },
   "outputs": [],
   "source": [
    "print(NER_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZDZklbuXBBy5"
   },
   "outputs": [],
   "source": [
    "print(NER_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hshsw96vBBy6"
   },
   "outputs": [],
   "source": [
    "NER_df.dropna(inplace=True)\n",
    "NER_df.drop(columns=[\"Sentence #\",\"POS\"],inplace=True)\n",
    "NER_df[\"Tag\"] = NER_df[\"Tag\"].apply(lambda x: ast.literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aV6L_uibBBy6"
   },
   "outputs": [],
   "source": [
    "print(NER_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lThaFLzmBBy6"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(NER_df[\"Sentence\"], NER_df[\"Tag\"], shuffle=True,test_size=0.20, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, shuffle=True,test_size=0.50, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vrCg2fD8BBy6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "X_tokenizer = Tokenizer(lower=False,oov_token=\"UNK\")\n",
    "X_tokenizer.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "faIbCZ_rBBy6"
   },
   "outputs": [],
   "source": [
    "X_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wo9bszb2BBy6"
   },
   "outputs": [],
   "source": [
    "X_train = X_tokenizer.texts_to_sequences(X_train)\n",
    "X_test = X_tokenizer.texts_to_sequences(X_test)\n",
    "X_val = X_tokenizer.texts_to_sequences(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5lLUJEHmBBy7"
   },
   "outputs": [],
   "source": [
    "vocab_len = len(X_tokenizer.word_index)\n",
    "print(f\"Number of unique tokens:\\t{vocab_len}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hXP7QrzBBy7"
   },
   "outputs": [],
   "source": [
    "train_tags = set([val for sublist in y_train for val in sublist])\n",
    "test_tags = set([val for sublist in y_test for val in sublist])\n",
    "val_tags = set([val for sublist in y_val for val in sublist])\n",
    "\n",
    "print(\"Unique NER tags in train set: \",train_tags)\n",
    "print(\"Unique NER tags in test set: \",test_tags)\n",
    "print(\"Unique NER tags in test set: \",val_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F7MFkqntBBy_"
   },
   "outputs": [],
   "source": [
    "y_tokenizer = Tokenizer(lower=False,oov_token=\"UNK\")\n",
    "y_tokenizer.fit_on_texts(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ndwk39paBBy_"
   },
   "outputs": [],
   "source": [
    "y_train = y_tokenizer.texts_to_sequences(y_train)\n",
    "y_test = y_tokenizer.texts_to_sequences(y_test)\n",
    "y_val = y_tokenizer.texts_to_sequences(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FpgMLGefBBy_"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for dataset in [X_train,X_test,X_val]:\n",
    "    for i in range(len(dataset)):\n",
    "        max_len = max(max_len,len(dataset[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ia8aGb_BBzA"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_len, padding=\"post\", value=0)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len, padding=\"post\", value=0)\n",
    "X_val = pad_sequences(X_val, maxlen=max_len, padding=\"post\", value=0)\n",
    "\n",
    "y_train = pad_sequences(y_train, maxlen=max_len, padding=\"post\", value=0)\n",
    "y_test = pad_sequences(y_test, maxlen=max_len, padding=\"post\", value=0)\n",
    "y_val = pad_sequences(y_val, maxlen=max_len, padding=\"post\", value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5kN0ObsBBzA"
   },
   "outputs": [],
   "source": [
    "for dataset in [X_train,X_test,X_val,y_train,y_test,y_val]:\n",
    "    print(dataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YqnJq70GBBzA"
   },
   "outputs": [],
   "source": [
    "Number_of_classes_K = len(y_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iUpTqnmmBBzA"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Input\n",
    "from keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(10,))\n",
    "dense_layer = Dense(32, activation='relu')(input_layer)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "output_layer = Dense(1, activation='sigmoid')(dropout_layer)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qmNdaanbBBzA"
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Input, Bidirectional, LSTM, Embedding, Dropout\n",
    "from keras.models import Model\n",
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ej6HRBszBBzA"
   },
   "outputs": [],
   "source": [
    "vector_size = 64\n",
    "\n",
    "input_layer = Input(shape=(max_len,))\n",
    "embedding_layer = Embedding(input_dim=vocab_len + 1, output_dim=vector_size, mask_zero=True, trainable=True)(input_layer)\n",
    "dropout_layer_1 = Dropout(0.2)(embedding_layer)\n",
    "bidirectional_LSTM_Layer = Bidirectional(LSTM(vector_size * 2, return_sequences=True))(dropout_layer_1)\n",
    "output_layer = Dense(Number_of_classes_K)(bidirectional_LSTM_Layer)\n",
    "\n",
    "model = Model(input_layer, output_layer)\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HhPjiVH3BBzA"
   },
   "outputs": [],
   "source": [
    "pprint(model.get_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aJj8FCvABBzB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlhgpaOCBBzB"
   },
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor (e.g., validation loss)\n",
    "    patience=3,          # Number of epochs with no improvement after which training will stop\n",
    "    restore_best_weights=True  # Restore the weights of the best epoch\n",
    ")\n",
    "model.compile(optimizer=\"adam\",loss=SparseCategoricalCrossentropy(from_logits=True),metrics=[\"accuracy\"])\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=6,\n",
    "    validation_data=(X_val, y_val),\n",
    "    callbacks=[early_stopping]  # Include EarlyStopping in callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5H5TGCoaBBzB"
   },
   "outputs": [],
   "source": [
    "sentence = \"\"\"Is this the real life? Is this just fantasy? Caught in a landslide, no escape from reality\"\"\"\n",
    "unpadded_len = len(sentence.split(\" \"))\n",
    "predictions = model.predict(pad_sequences(X_tokenizer.texts_to_sequences([sentence]),\n",
    "                                          maxlen=max_len,\n",
    "                                         padding=\"post\"))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOhZDwq4BBzB"
   },
   "outputs": [],
   "source": [
    "prediction_ner = np.argmax(predictions,axis=-1)\n",
    "print(prediction_ner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9RlEcZU0BBzB"
   },
   "outputs": [],
   "source": [
    "NER_tags = [y_tokenizer.index_word[num] for num in list(prediction_ner.flatten())][:unpadded_len]\n",
    "print(NER_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iIV0z55_BBzC"
   },
   "outputs": [],
   "source": [
    "sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XJTDkLFmBBzC"
   },
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    print(\"Name:\", gpu.name, \"  Type:\", gpu.device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zOxg0qR1BBzC"
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j-smtIDCBBzC"
   },
   "outputs": [],
   "source": [
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Op38PT3UBBzD"
   },
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkML7-gaBBzD"
   },
   "outputs": [],
   "source": [
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mKlztf0FBBzD"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "  tf.keras.layers.Dense(128, activation='relu'),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dFbWj10DBBzD"
   },
   "outputs": [],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BLAAxH6XBBzD"
   },
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-tDSVGrtBBzE"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "47EH8pYIBBzE"
   },
   "outputs": [],
   "source": [
    "tf.device('/device:GPU:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GT6VU6TkBBzE"
   },
   "outputs": [],
   "source": [
    "with tf.device('/device:GPU:0'):\n",
    "    model.fit(x_train, y_train, epochs=500, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BXygTPHBBzE"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "81dmAWPCBBzE"
   },
   "outputs": [],
   "source": [
    "predictions = model(x_test[:1]).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZIk1Cj40BBzE"
   },
   "outputs": [],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "include_colab_link": true,
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "databundleVersionId": 3092179,
     "datasetId": 1861688,
     "sourceId": 3043695,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30920,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
