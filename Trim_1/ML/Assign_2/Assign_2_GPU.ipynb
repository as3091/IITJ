{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C4H9-TYwzwgk"
      },
      "source": [
        "Q3: Implementation of Neural Networks from Scratch Using NumPy and Comparison with Sklearn (20 marks):\n",
        "  \n",
        "    1. Load and preprocess the MNIST Digits Dataset. (3 marks)\n",
        "    2. Implement a neural network with one input layer, one hidden layer, and one output layer using NumPy. (5 marks)\n",
        "    3. Train the neural network with various hyperparameters (e.g., learning rate, number of hidden nodes). (3 marks)\n",
        "    4. Evaluate the performance of the neural network on the testing set. (2 marks)\n",
        "    5. Implement the same neural network using sklearn and compare the results with the NumPy implementation. (4 marks)\n",
        "    6. Plot the training and validation loss/accuracy curves (for both experiments). (3 marks)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "5fi7HVHozwgm"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from IPython.display import display, HTML\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "import warnings,gc,sys\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.metrics import accuracy_score,confusion_matrix,ConfusionMatrixDisplay, classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    try:\n",
        "        mnist_784_df = pd.read_csv(\"mnist_784.csv\")\n",
        "        break\n",
        "    except FileNotFoundError:\n",
        "        from sklearn.datasets import fetch_openml\n",
        "\n",
        "        X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
        "        X[\"Y\"] = y\n",
        "        X.to_csv(\"mnist_784.csv\",index=False,header=True)\n",
        "        del X,y\n",
        "# %%script echo skipping"
      ],
      "metadata": {
        "id": "n56hga1meEh-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Load MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Preprocess data\n",
        "def preprocess(x, y):\n",
        "    x = tf.reshape(x, shape=(-1, 28*28))  # Flatten images to 784-dimensional vectors\n",
        "    x = tf.cast(x, tf.float32) / 255.0    # Normalize pixel values\n",
        "    y = tf.one_hot(y, depth=10)           # One-hot encode labels\n",
        "    return x, y\n",
        "\n",
        "# Prepare datasets\n",
        "# train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train)).map(preprocess).batch(128)\n",
        "# test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test)).map(preprocess).batch(128)\n",
        "\n",
        "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((x_test, y_test))"
      ],
      "metadata": {
        "id": "SCMMxhF17wgv"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize parameters manually (no Keras layers)\n",
        "input_size = 784\n",
        "hidden_size = 256\n",
        "output_size = 10\n",
        "\n",
        "# Weights and biases for hidden layer 1\n",
        "W1 = tf.Variable(tf.random.truncated_normal([input_size, hidden_size], stddev=0.1))\n",
        "b1 = tf.Variable(tf.zeros([hidden_size]))\n",
        "\n",
        "# Weights and biases for output layer\n",
        "W2 = tf.Variable(tf.random.truncated_normal([hidden_size, output_size], stddev=0.1))\n",
        "b2 = tf.Variable(tf.zeros([output_size]))"
      ],
      "metadata": {
        "id": "TjeyhP8Q7zpy"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(x):\n",
        "    x = tf.reshape(x, shape=(-1, input_size))\n",
        "    # Hidden layer with ReLU activation\n",
        "    z1 = tf.matmul(x, W1) + b1\n",
        "    a1 = tf.nn.relu(z1)\n",
        "\n",
        "    # Output layer (logits)\n",
        "    logits = tf.matmul(a1, W2) + b2\n",
        "    return logits"
      ],
      "metadata": {
        "id": "fdOkBgAx77gh"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function (cross-entropy)\n",
        "loss_fn = tf.losses.CategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Optimizer (Adam)\n",
        "optimizer = tf.optimizers.Adam(learning_rate=0.001)"
      ],
      "metadata": {
        "id": "iwg2R-7e79uM"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10**3\n",
        "with tf.device('/device:GPU:0'):\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0.0\n",
        "\n",
        "        # Training loop\n",
        "        for x_batch, y_batch in train_data:\n",
        "            with tf.GradientTape() as tape:\n",
        "                logits = forward(x_batch)\n",
        "                loss = loss_fn(y_batch, logits)\n",
        "\n",
        "            # Compute gradients and update weights\n",
        "            gradients = tape.gradient(loss, [W1, b1, W2, b2])\n",
        "            optimizer.apply_gradients(zip(gradients, [W1, b1, W2, b2]))\n",
        "            total_loss += loss.numpy()\n",
        "\n",
        "        # Print epoch loss\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/len(train_data):.4f}\")"
      ],
      "metadata": {
        "id": "KAJ5C-g47_sw",
        "outputId": "34ed60bb-6863-447b-f05b-5e6114d8f129",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000, Loss: 0.3271\n",
            "Epoch 2/1000, Loss: 0.1419\n",
            "Epoch 3/1000, Loss: 0.0968\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-64-428bdf907745>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0;31m# Compute gradients and update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mgradients\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m             \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    447\u001b[0m             \u001b[0;31m# Apply gradient updates.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 448\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend_apply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    449\u001b[0m             \u001b[0;31m# Apply variable constraints after applying gradients.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mvariable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36m_backend_apply_gradients\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m             \u001b[0;31m# Run update step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m             self._backend_update_step(\n\u001b[0m\u001b[1;32m    512\u001b[0m                 \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_backend_update_step\u001b[0;34m(self, grads, trainable_variables, learning_rate)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0mgrads_and_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_all_reduce_sum_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         tf.__internal__.distribute.interim.maybe_merge_call(\n\u001b[0m\u001b[1;32m    121\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distributed_tf_update_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_distribution_strategy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/merge_call_interim.py\u001b[0m in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m   \"\"\"\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mstrategy_supports_no_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     return distribute_lib.get_replica_context().merge_call(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36m_distributed_tf_update_step\u001b[0;34m(self, distribution, grads_and_vars, learning_rate)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m             distribution.extended.update(\n\u001b[0m\u001b[1;32m    135\u001b[0m                 \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3003\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   3004\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3005\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3006\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3007\u001b[0m       return self._replica_ctx_update(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4073\u001b[0m     \u001b[0;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4074\u001b[0m     \u001b[0;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4075\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4076\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4077\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4079\u001b[0m     \u001b[0;31m# once that value is used for something.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4080\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4081\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4082\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4083\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUNSPECIFIED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad, learning_rate)\u001b[0m\n\u001b[1;32m    129\u001b[0m     ):\n\u001b[1;32m    130\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mapply_grad_to_update_var\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mupdate_step\u001b[0;34m(self, gradient, variable, learning_rate)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubtract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbeta_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         )\n\u001b[0;32m--> 135\u001b[0;31m         self.assign_add(\n\u001b[0m\u001b[1;32m    136\u001b[0m             \u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             ops.multiply(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, variable, value)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0mvariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massign_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massign_sub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36massign_add\u001b[0;34m(self, delta, use_locking, name, read_value)\u001b[0m\n\u001b[1;32m   1045\u001b[0m           name=name)\n\u001b[1;32m   1046\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mread_value\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0massign_add_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0massign_add_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_lazy_read\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   1050\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_lazy_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m     \u001b[0mvariable_accessed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m     return _UnreadVariable(\n\u001b[0m\u001b[1;32m   1053\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, handle, dtype, shape, in_graph_mode, parent_op, unique_id)\u001b[0m\n\u001b[1;32m   2403\u001b[0m             handle, dtype)\n\u001b[1;32m   2404\u001b[0m         \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2405\u001b[0;31m     super(_UnreadVariable, self).__init__(\n\u001b[0m\u001b[1;32m   2406\u001b[0m         \u001b[0mhandle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2407\u001b[0m         \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, trainable, shape, dtype, handle, constraint, synchronization, aggregation, distribute_strategy, name, unique_id, handle_name, graph_element, initial_value, initializer_op, is_initialized_op, cached_value, save_slice_info, caching_device, in_graph_mode, validate_shape, **unused_kwargs)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;31m# Store the graph key so optimizers know how to only retrieve variables from\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[0;31m# this graph. Guaranteed to be the same as the eager graph_key.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_key\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_key\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_default_graph\u001b[0;34m()\u001b[0m\n\u001b[1;32m   5115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5117\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtf_export\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"get_default_graph\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5118\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mGraph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5119\u001b[0m   \"\"\"Returns the default graph for the current thread.\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "krzMmnmszwgn"
      },
      "outputs": [],
      "source": [
        "def sigmoid(x):\n",
        "    return tf.sigmoid(x)\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)  # Remains the same\n",
        "\n",
        "def relu(x):\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return tf.cast(tf.greater(x, 0), tf.float32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "IXEsaD_Szwgo",
        "outputId": "3999aeb5-93a3-48dc-b0ae-b10409f387e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "784 27\n"
          ]
        }
      ],
      "source": [
        "inputs = mnist_784_df.drop(columns=\"Y\").values\n",
        "targets = mnist_784_df[\"Y\"].values\n",
        "result = np.where(targets == 5, 1, 0)\n",
        "\n",
        "IL_n = mnist_784_df.shape[-1]-1\n",
        "n_neurons_HL = int(np.sqrt(IL_n-1))\n",
        "print(IL_n,n_neurons_HL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "3j3G-xCfzwgo"
      },
      "outputs": [],
      "source": [
        "# Normalize the array\n",
        "max_values = np.max(inputs, axis=0)\n",
        "min_values = np.min(inputs, axis=0)\n",
        "\n",
        "normalized_array = (inputs - min_values) / (max_values - min_values)\n",
        "normalized_array = np.nan_to_num(normalized_array)  # Replace NaN values with 0\n",
        "\n",
        "# normalized_array = tf.convert_to_tensor(normalized_array, dtype=tf.float32)\n",
        "# targets = tf.reshape(tf.convert_to_tensor(targets, dtype=tf.float32),shape = (-1,1))\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "# index = 101\n",
        "# print(normalized_array[index])\n",
        "# plt.imshow(normalized_array[index].reshape(28, 28), cmap='gray')\n",
        "# plt.title(f'{result[index]}')\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "npTr9DU3zwgo"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "inputs = pd.DataFrame(scaler.fit_transform(inputs), columns=inputs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%script echo skipping\n",
        "# # Create a tf.data.Dataset from your data\n",
        "# dataset = tf.data.Dataset.from_tensor_slices((normalized_array, targets))\n",
        "\n",
        "# # Split the dataset into train and test sets\n",
        "# train_dataset, test_dataset = tf.keras.utils.split_dataset(\n",
        "#     dataset,\n",
        "#     left_size=0.8,  # Proportion for the train set (80% in this case)\n",
        "#     right_size=0.2,  # Proportion for the test set (20% in this case)\n",
        "#     shuffle=True, seed = 42\n",
        "# )"
      ],
      "metadata": {
        "id": "T_sZi9L1oagM",
        "outputId": "09167cc2-d0fe-4286-c3b6-9f37b8d8ecbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "skipping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    normalized_array, result,\n",
        "    test_size=0.20, random_state=42,\n",
        "    stratify=result,shuffle=True)"
      ],
      "metadata": {
        "id": "jnsRYY9spSQ9"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [X_train, X_test, y_train, y_test]:\n",
        "    print(i.shape)\n"
      ],
      "metadata": {
        "id": "VSes6BdQyVyP",
        "outputId": "1b18df0c-f872-441b-8ded-0679de95a5c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784)\n",
            "(14000, 784)\n",
            "(56000,)\n",
            "(14000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "svaq-NFAzwgo"
      },
      "outputs": [],
      "source": [
        "# X_train, X_test, y_train, y_test\n",
        "\n",
        "X_train = tf.convert_to_tensor(X_train, dtype=tf.float32)\n",
        "X_test = tf.convert_to_tensor(X_test, dtype=tf.float32)\n",
        "\n",
        "y_train = tf.reshape(tf.convert_to_tensor(y_train, dtype=tf.float32),shape = (-1,1))\n",
        "y_test = tf.reshape(tf.convert_to_tensor(y_test, dtype=tf.float32),shape = (-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in [X_train, X_test, y_train, y_test]:\n",
        "    print(i.shape)\n"
      ],
      "metadata": {
        "id": "OABu-PMTycN6",
        "outputId": "9959c904-c776-4caf-9d31-61b0921803be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(56000, 784)\n",
            "(14000, 784)\n",
            "(56000, 1)\n",
            "(14000, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values and their counts\n",
        "for i in y_train, y_test:\n",
        "    unique_values, _, counts = tf.unique_with_counts(tf.reshape(i,shape = (-1,)))\n",
        "\n",
        "    # Print the results\n",
        "    print(\"Unique Values:\", unique_values.numpy())\n",
        "    print(\"Counts:\", counts.numpy())"
      ],
      "metadata": {
        "id": "asdsFwAmx0rt",
        "outputId": "3ed28062-fff1-438d-983c-65108495c67a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Values: [0. 1.]\n",
            "Counts: [50950  5050]\n",
            "Unique Values: [0. 1.]\n",
            "Counts: [12737  1263]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "6yVmSs2yzwgo"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim,inputs, targets):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.inputs = inputs\n",
        "        # tf.convert_to_tensor(inputs, dtype=tf.float32)\n",
        "        self.targets = targets\n",
        "        # tf.convert_to_tensor(targets.reshape(-1, 1), dtype=tf.float32)\n",
        "\n",
        "        self.weights1 = tf.random.normal((self.input_dim, self.hidden_dim))\n",
        "        self.weights2 = tf.random.normal((self.hidden_dim, self.output_dim))\n",
        "        self.bias1 = tf.zeros((1, self.hidden_dim))\n",
        "        self.bias2 = tf.zeros((1, self.output_dim))\n",
        "\n",
        "    def sigmoid(self,x):\n",
        "        return tf.sigmoid(x)\n",
        "    def sigmoid_derivative(self,x):\n",
        "        return x * (1 - x)\n",
        "    def relu(self,x):\n",
        "        return tf.nn.relu(x)\n",
        "    def relu_derivative(self,x):\n",
        "        return tf.cast(tf.greater(x, 0), tf.float32)\n",
        "\n",
        "    def forward_propagation(self,input ):\n",
        "\n",
        "        hidden_layer_input = tf.matmul(input, self.weights1) + self.bias1\n",
        "        self.hidden_layer_output = tf.nn.relu(hidden_layer_input)\n",
        "\n",
        "        output_layer_input = tf.matmul(self.hidden_layer_output, self.weights2) + self.bias2\n",
        "        self.output_layer_output = tf.sigmoid(output_layer_input)\n",
        "\n",
        "        # # print(tf.reshape(y_pred,shape = (-1,)))\n",
        "        # condition = tf.greater(self.output_layer_output, .5)  # threshold\n",
        "        # indices = tf.where(condition)          # Get indices where condition is True\n",
        "\n",
        "        # # # Equivalent to np.where(tensor_data > 3, tensor_data, 0)\n",
        "        # y_pred = tf.where(condition, 1, tf.zeros_like(self.output_layer_output))\n",
        "\n",
        "        # # Get unique values and their counts\n",
        "        # unique_values, _, counts = tf.unique_with_counts(tf.reshape(y_pred,shape = (-1,)))\n",
        "\n",
        "        # # Print the results\n",
        "        # print(\"Unique Values:\", unique_values.numpy())\n",
        "        # print(\"Counts:\", counts.numpy())\n",
        "        # sys.exit()\n",
        "\n",
        "    def backward_propagation(self):\n",
        "\n",
        "        d_output =self.output_layer_output - self.targets\n",
        "\n",
        "        self.d_weights2 = tf.matmul(tf.transpose(self.hidden_layer_output), d_output * self.sigmoid_derivative(self.output_layer_output))\n",
        "\n",
        "        self.d_bias2 = tf.reduce_sum(d_output * self.sigmoid_derivative(self.output_layer_output), axis=0, keepdims=True)\n",
        "\n",
        "        d_hidden_layer = tf.matmul(d_output * self.sigmoid_derivative(self.output_layer_output), tf.transpose(self.weights2)) * self.relu_derivative(self.hidden_layer_output)\n",
        "\n",
        "        self.d_weights1 = tf.matmul(tf.transpose(self.inputs), d_hidden_layer)\n",
        "        self.d_bias1 = tf.reduce_sum(d_hidden_layer, axis=0, keepdims=True)\n",
        "\n",
        "    def update_weights(self,learning_rate):\n",
        "\n",
        "        self.weights1 -= learning_rate * self.d_weights1\n",
        "        self.bias1 -= learning_rate * self.d_bias1\n",
        "        self.weights2 -= learning_rate * self.d_weights2\n",
        "        self.bias2 -= learning_rate * self.d_bias2\n",
        "\n",
        "    def fit(self, epochs, learning_rate):\n",
        "\n",
        "        for epoch in tqdm(range(epochs),leave=False):\n",
        "\n",
        "            self.forward_propagation(input=self.inputs)\n",
        "            self.backward_propagation()\n",
        "            self.update_weights(learning_rate=learning_rate)\n",
        "\n",
        "                # Print loss every 1000 epochs\n",
        "            if epoch % (epochs//10) == 0:\n",
        "                loss = tf.reduce_mean(tf.square(self.output_layer_output - self.targets))\n",
        "                print(f\"\\nEpoch {epoch+1}, Loss: {loss}\")\n",
        "                # gc.collect()\n",
        "\n",
        "        # _, final_output =\n",
        "    def predict(self,input):\n",
        "            self.forward_propagation(input=tf.convert_to_tensor(input, dtype=tf.float32))\n",
        "            # print(\"Final Predictions:\")\n",
        "            return self.output_layer_output\n",
        "            # print(self.output_layer_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "g-sdgAIizwgp",
        "outputId": "912e0f39-9907-4d52-d50a-f95d6a71d5eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                        "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Values: [1. 0.]\n",
            "Counts: [30108 25892]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-8a53ae5e39fb>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, epochs, learning_rate)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-8a53ae5e39fb>\u001b[0m in \u001b[0;36mforward_propagation\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unique Values:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_values\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Counts:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: "
          ]
        }
      ],
      "source": [
        "%%time\n",
        "with tf.device('/device:GPU:0'):\n",
        "    nn = NeuralNetwork(input_dim=IL_n, hidden_dim=n_neurons_HL, output_dim=1,inputs=X_train,targets=y_train)\n",
        "    # X_train, X_test, y_train, y_test\n",
        "    learning_rate = 0.01\n",
        "    epochs = 10**3\n",
        "    nn.fit(epochs, learning_rate)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = nn.predict(input=X_test)\n",
        "print(y_pred)\n",
        "# print(tf.reshape(y_pred,shape = (-1,)))\n",
        "# condition = tf.greater(y_pred, .5)  # threshold\n",
        "# indices = tf.where(condition)          # Get indices where condition is True\n",
        "\n",
        "# # # Equivalent to np.where(tensor_data > 3, tensor_data, 0)\n",
        "# y_pred = tf.where(condition, y_pred, tf.zeros_like(y_pred))"
      ],
      "metadata": {
        "id": "ZquyFYNbgw68",
        "outputId": "23acc26a-9b8b-4e94-b1c2-5236b4eb23cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0.]\n",
            " [0.]\n",
            " [0.]\n",
            " ...\n",
            " [0.]\n",
            " [0.]\n",
            " [0.]], shape=(14000, 1), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get unique values and their counts\n",
        "unique_values, _, counts = tf.unique_with_counts(tf.reshape(y_pred,shape = (-1,)))\n",
        "\n",
        "# Print the results\n",
        "print(\"Unique Values:\", unique_values.numpy())\n",
        "print(\"Counts:\", counts.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wfz7XJyCtZ8G",
        "outputId": "21ec30eb-5849-4a9b-b5ec-33ca7df3e55c"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique Values: [0.]\n",
            "Counts: [14000]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_test = tf.reshape(y_test,shape = (-1,1))"
      ],
      "metadata": {
        "id": "VzJNDw5Djx0d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tf.reshape(y_pred,shape = (-1,1))"
      ],
      "metadata": {
        "id": "j0iwqC7TjzAZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.metrics import accuracy_score, classification_report\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "id": "nTiingfRjQM3",
        "outputId": "8eee4555-e66e-432e-9a93-60da9a9e325c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_test, y_pred)\n",
        "# Get the unique class labels from y_test\n",
        "unique_labels = np.unique(y_test)\n",
        "# Use unique_labels for display_labels\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=unique_labels)\n",
        "disp.plot()\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=unique_labels.astype(str))) # Convert to string for report"
      ],
      "metadata": {
        "id": "DqVfjGbfs602",
        "outputId": "aed523a8-a446-4f91-f523-deb24138f62f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      1.00      0.95      6369\n",
            "         1.0       0.00      0.00      0.00       631\n",
            "\n",
            "    accuracy                           0.91      7000\n",
            "   macro avg       0.45      0.50      0.48      7000\n",
            "weighted avg       0.83      0.91      0.87      7000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(recall, precision, marker='.', label=f'PR AUC = {pr_auc:.4f}')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall Curve')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PNZE8r4fi4Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys.exit()"
      ],
      "metadata": {
        "id": "mcBrCmOZz-z0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a726cixezwgp"
      },
      "outputs": [],
      "source": [
        "nn = NeuralNetwork(input_dim=IL_n, hidden_dim=n_neurons_HL, output_dim=1,input=inputs,targets=targets)\n",
        "\n",
        "\n",
        "learning_rate = 0.1\n",
        "epochs = 10000\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    hidden_layer_output, output_layer_output = nn.forward_propagation(inputs)\n",
        "    d_weights1, d_bias1, d_weights2, d_bias2 = nn.backward_propagation(inputs, targets, hidden_layer_output, output_layer_output)\n",
        "    nn.update_weights(d_weights1, d_bias1, d_weights2, d_bias2, learning_rate)\n",
        "\n",
        "    # Print loss every 1000 epochs\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(output_layer_output - targets))\n",
        "        print(f\"Epoch {epoch+1}, Loss: {loss}\")\n",
        "\n",
        "# Final predictions\n",
        "_, final_output = nn.forward_propagation(inputs)\n",
        "print(\"Final Predictions:\")\n",
        "print(final_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tPVz0TpRzwgq"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    def __init__(self,value):\n",
        "        self.value = value\n",
        "class hidden_layer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ro2I9jRzwgq"
      },
      "outputs": [],
      "source": [
        "class aHL:\n",
        "    def __init__(self,mnist_784_df):\n",
        "\n",
        "\n",
        "    def forward_prop_relu(self,input,weight):\n",
        "        return np.maximum(0, input*weight)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_uJ6esozwgq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RZzGoFwEzwgq"
      },
      "outputs": [],
      "source": [
        "X.to_csv(\"mnist_784.csv\",index=False,header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sZXE9q0Dzwgq"
      },
      "outputs": [],
      "source": [
        "display(X.head().T)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fwc70PtQzwgq"
      },
      "outputs": [],
      "source": [
        "df = pd.DataFrame(X, columns=[f'Pixel_{i}'for i in range(X.shape[-1])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o49d8VNhzwgq"
      },
      "outputs": [],
      "source": [
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J_SCsMTzzwgq"
      },
      "outputs": [],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bAYQJN6Czwgq"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork:\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim,inputs, targets):\n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.output_dim = output_dim\n",
        "\n",
        "        self.inputs = inputs\n",
        "        self.targets = targets\n",
        "\n",
        "        self.weights1 = np.random.rand(input_dim, hidden_dim)\n",
        "        self.weights2 = np.random.rand(hidden_dim, output_dim)\n",
        "        self.bias1 = np.zeros((1, hidden_dim))\n",
        "        self.bias2 = np.zeros((1, output_dim))\n",
        "\n",
        "    def forward_propagation(self):\n",
        "\n",
        "        hidden_layer_input = np.dot(self.inputs, self.weights1) + self.bias1\n",
        "        hidden_layer_output = relu(hidden_layer_input)\n",
        "\n",
        "        output_layer_input = np.dot(hidden_layer_output, self.weights2) + self.bias2\n",
        "        output_layer_output = sigmoid(output_layer_input)\n",
        "\n",
        "        return hidden_layer_output, output_layer_output\n",
        "\n",
        "    def backward_propagation(self, targets, hidden_layer_output, output_layer_output):\n",
        "\n",
        "        d_output = 2 * (output_layer_output - targets)\n",
        "        d_weights2 = np.dot(hidden_layer_output.T, d_output * sigmoid_derivative(output_layer_output))\n",
        "        d_bias2 = np.sum(d_output * sigmoid_derivative(output_layer_output), axis=0, keepdims=True)\n",
        "\n",
        "        d_hidden_layer = np.dot(d_output * sigmoid_derivative(output_layer_output), self.weights2.T) * relu_derivative(hidden_layer_output)\n",
        "        d_weights1 = np.dot(self.inputs.T, d_hidden_layer)\n",
        "        d_bias1 = np.sum(d_hidden_layer, axis=0, keepdims=True)\n",
        "\n",
        "        return d_weights1, d_bias1, d_weights2, d_bias2\n",
        "\n",
        "    def update_weights(self, d_weights1, d_bias1, d_weights2, d_bias2, learning_rate):\n",
        "        self.weights1 -= learning_rate * d_weights1\n",
        "        self.bias1 -= learning_rate * d_bias1\n",
        "        self.weights2 -= learning_rate * d_weights2\n",
        "        self.bias2 -= learning_rate * d_bias2\n",
        "\n",
        "    def runner(self, epochs, learning_rate):\n",
        "        # inputs, targets, epochs, learning_rate\n",
        "        for i in range(epochs):\n",
        "            # hidden_layer_output, output_layer_output = self.forward_propagation(inputs)\n",
        "            # d_weights1, d_bias1, d_weights2, d_bias2 = self.backward_propagation(inputs, targets, hidden_layer_output, output_layer_output)\n",
        "            # self.update_weights(d_weights1, d_bias1, d_weights2, d_bias2, learning_rate)\n",
        "\n",
        "            self.forward_propagation()\n",
        "            self.backward_propagation()\n",
        "            self.update_weights()\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                print(f\"Loss: {np.mean(np.square(output_layer_output - targets))}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "cell_execution_strategy": "setup"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}